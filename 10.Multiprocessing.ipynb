{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Map reduce example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import sleep\n",
    "def delayed_square(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "data = list(range(8))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 ms, sys: 1.04 ms, total: 2.1 ms\n",
      "Wall time: 8.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum([delayed_square(x) for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 ms, sys: 1.18 ms, total: 2.63 ms\n",
      "Wall time: 8.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sum(map(delayed_square,data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can process each `delayed_square` calls independently and in parallel.  To accomplish this we'll apply that function across all list items in parallel using multiple processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thread and Process: Differences\n",
    "\n",
    "- A Process is an instance of a running program. \n",
    "- Process may contain one or more threads, but a thread cannot contain a process.\n",
    "- Process has a self-contained execution environment. It has its own memory space. \n",
    "- Application running on your computer may be a set of cooperating processes.\n",
    "\n",
    "- A Thread is made of and exist within a Process; every process has at least one. \n",
    "- Multiple threads in a process share resources, which helps in efficient communication between threads.\n",
    "- Threads can be concurrent on a multi-core system, with every core executing the separate threads simultaneously.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-Processing vs Multi-Threading\n",
    "\n",
    "### Memory\n",
    "- Each process has its own copy of the data segment of the parent process.\n",
    "- Each thread has direct access to the data segment of its process.\n",
    "- A process runs in separate memory spaces.\n",
    "- A thread runs in shared memory spaces.\n",
    "\n",
    "### Communication\n",
    "- Processes must use inter-process communication to communicate with sibling processes.\n",
    "- Threads can directly communicate with other threads of its process.\n",
    "\n",
    "### Overheads\n",
    "- Processes have considerable overhead.\n",
    "- Threads have almost no overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-Processing vs Multi-Threading\n",
    "\n",
    "### Creation\n",
    "- New processes require duplication of the parent process.\n",
    "- New threads are easily created.  \n",
    "\n",
    "### Control\n",
    "- Processes can only exercise control over child processes.\n",
    "- Threads can exercise considerable control over threads of the same process.\n",
    "\n",
    "### Changes\n",
    "- Any change in the parent process does not affect child processes.\n",
    "- Any change in the main thread may affect the behavior of the other threads of the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Global Interpreter Lock (GIL)\n",
    "\n",
    "- The Python interpreter is not thread safe.\n",
    "- A few critical internal data structures may only be accessed by one thread at a time. Access to them is protected by the GIL.\n",
    "- Attempts at removing the GIL from Python have failed until now. The main difficulty is maintaining the C API for extension modules.\n",
    "- Multiprocessing avoids the GIL by having separate processes which each have an independent copy of the interpreter data structures.\n",
    "- The price to pay: serialization of tasks, arguments, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiprocessing (history)\n",
    "\n",
    "- The multiprocessing allows the programmer to fully leverage multiple processors. \n",
    "- The `Pool` object parallelizes the execution of a function across multiple input values.\n",
    "- The if `__name__ == '__main__'` part is necessary.\n",
    "<p><font color=red> The next cell will not work on Windows </font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 ms, sys: 14.9 ms, total: 25.1 ms\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "assert(os.name != 'nt')\n",
    "    \n",
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__': # Executed only on main process.\n",
    "    with Pool(4) as p:\n",
    "        result = sum(p.map(delayed_square, data))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with threads, using ThreadPoolExecutor, or separate processes, using ProcessPoolExecutor. Both implement the same interface, which is defined by the abstract Executor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 23.9 ms, total: 39.5 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "if os.name == \"nt\":\n",
    "    from loky import ProcessPoolExecutor  # for Windows users \n",
    "else:\n",
    "    from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def delayed_square(x):\n",
    "    sleep(1)\n",
    "    return x*x\n",
    "\n",
    "e = ProcessPoolExecutor()\n",
    "\n",
    "results = list(e.map(delayed_square, range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.59 ms, sys: 3.13 ms, total: 5.72 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "e = ThreadPoolExecutor()\n",
    "\n",
    "results = list(e.map(delayed_square, range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Asynchronous Future\n",
    "While many parallel applications can be described as maps, some can be more complex. In this section we look at the asynchronous Future interface, which provides a simple API for ad-hoc parallelism. This is useful for when your computations don't fit a regular pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Executor.submit\n",
    "\n",
    "The `submit` method starts a computation in a separate thread or process and immediately gives us a `Future` object that refers to the result.  At first, the future is pending.  Once the function completes the future is finished. \n",
    "\n",
    "We collect the result of the task with the `.result()` method,\n",
    "which does not return until the results are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def slowadd(a, b, delay=1):\n",
    "    sleep(delay)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x1069ef240 state=running>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor(4)\n",
    "future = e.submit(slowadd, 1, 2)\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Submit many tasks all at once and they be will executed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 ms, sys: 1.16 ms, total: 2.29 ms\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = [slowadd(i, i, delay=1) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.27 ms, sys: 2.52 ms, total: 4.78 ms\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "futures = [e.submit(slowadd, 1, 1, delay=1) for i in range(8)]\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*  Submit fires off a single function call in the background, returning a future.  \n",
    "*  When you combine submit with a single for loop we recover the functionality of map.  \n",
    "*  To collect your results, replace each of futures, `f`, with a call to `f.result()`\n",
    "*  Combine submit with multiple for loops and other general programming to get something more general than map.\n",
    "*  Sometimes, it did not speed up the code very much\n",
    "*  Threads and processes show some performance differences\n",
    "*  Use threads carefully, you can break your Python session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today most library designers are coordinating around the concurrent.futures interface, so it's wise to move over.\n",
    "\n",
    "* Profile your code\n",
    "* Used concurrent.futures.ProcessPoolExecutor for simple parallelism \n",
    "* Gained some speed boost (but not as much as expected)\n",
    "* Lost ability to diagnose performance within parallel code\n",
    "* Describing each task as a function call helps use tools like map for parallelism\n",
    "* Making your tasks fast is often at least as important as parallelizing your tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise: Pi computation\n",
    "\n",
    "Parallelize this computation with a ProcessPoolExecutor. ThreadPoolExecutor is not usable because of `random` function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value of Pi : 3.14142260 time : 14.21694803\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def compute_pi(n):\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if x*x + y*y <= 1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "elapsed_time = time.time()\n",
    "nb_simulations = 4\n",
    "n = 10**7\n",
    "result = [compute_pi(n) for i in range(nb_simulations)]\n",
    "pi = 4 * sum(result) / (n*nb_simulations)\n",
    "print(f\"Estimated value of Pi : {pi:.8f} time : {time.time()-elapsed_time:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Do the same computation using asynchronous future\n",
    "- Implement a joblib version (see example below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Joblib (bonus)\n",
    "\n",
    "[Joblib](http://pythonhosted.org/joblib/) provides a simple helper class to write parallel for loops using multiprocessing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.8 ms, sys: 29.2 ms, total: 84 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=8)(delayed(f)(x) for x in range(8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
